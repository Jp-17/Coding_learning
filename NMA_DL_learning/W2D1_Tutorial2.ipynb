{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {},
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/NeuromatchAcademy/course-content-dl/blob/main/tutorials/W2D1_ConvnetsAndRecurrentNeuralNetworks/student/W2D1_Tutorial2.ipynb\" target=\"_blank\"><img alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"/></a> Â  <a href=\"https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D1_ConvnetsAndRecurrentNeuralNetworks/student/W2D1_Tutorial2.ipynb\" target=\"_blank\"><img alt=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Tutorial 2: Introduction to RNNs\n",
    "\n",
    "**Week 2, Day 1: Convnets And Recurrent Neural Networks**\n",
    "\n",
    "**By Neuromatch Academy**\n",
    "\n",
    "__Content creators:__ Dawn McKnight, Richard Gerum, Cassidy Pirlot, Rohan Saha, Liam Peet-Pare, Saeed Najafi, Alona Fyshe\n",
    "\n",
    "__Content reviewers:__ Saeed Salehi, Lily Cheng, Yu-Fang Yang, Polina Turishcheva, Nina Kudryashova, Kelson Shilling-Scrivo\n",
    "\n",
    "__Content editors:__ Gagana B, Nina Kudryashova\n",
    "\n",
    "__Production editors:__ Anmol Gupta, Spiros Chavlis \n",
    "\n",
    "__Post-Production team:__ Gagana B, Spiros Chavlis\n",
    "\n",
    "*Based on material from:* Konrad Kording, Hmrishav Bandyopadhyay, Rahul Shekhar, Tejas Srivastava"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "**Our 2021 Sponsors, including Presenting Sponsor Facebook Reality Labs**\n",
    "\n",
    "<p align='center'><img src='https://github.com/NeuromatchAcademy/widgets/blob/master/sponsors.png?raw=True'/></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Tutorial Objectives\n",
    "At the end of this tutorial, we will be able to:\n",
    "- Understand the structure of a Recurrent Neural Network (RNN)\n",
    "- Build a simple RNN model\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Tutorial slides\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"854\"\n",
       "            height=\"480\"\n",
       "            src=\"https://mfr.ca-1.osf.io/render?url=https://osf.io/5asx2/?direct%26mode=render%26action=download%26mode=render\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1d29a9eea20>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title Tutorial slides\n",
    "\n",
    "from IPython.display import IFrame\n",
    "IFrame(src=f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/5asx2/?direct%26mode=render%26action=download%26mode=render\", width=854, height=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "These are the slides for the videos in this tutorial. If you want to download locally the slides, click [here](https://osf.io/5asx2/download).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Install dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Install dependencies\n",
    "!pip install livelossplot --quiet\n",
    "!pip install unidecode --quiet\n",
    "\n",
    "!pip install git+https://github.com/NeuromatchAcademy/evaltools --quiet\n",
    "from evaltools.airtable import AirtableForm\n",
    "\n",
    "# Generate airtable form\n",
    "atform = AirtableForm('appn7VdPRseSoMXEG','W2D1_T2','https://portal.neuromatchacademy.org/api/redirect/to/351ca652-13d8-4e31-be28-30153d03e639')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the module 'TimeoutError' could not be imported.\n",
      "Click <a href='https://aka.ms/kernelFailuresModuleImportErr'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import string\n",
    "import random\n",
    "import unidecode\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Figure settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Figure settings\n",
    "import ipywidgets as widgets       # Interactive display\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/content-creation/main/nma.mplstyle\")\n",
    "\n",
    "plt.rcParams[\"mpl_toolkits.legacy_colorbar\"] = False\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"matplotlib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Helper functions\n",
    "# https://github.com/spro/char-rnn.pytorch\n",
    "\n",
    "def read_file(filename):\n",
    "  \"\"\"\n",
    "  Helper function to read file\n",
    "\n",
    "  Args:\n",
    "    filename: string\n",
    "      FileName\n",
    "\n",
    "  Returns:\n",
    "    file: string\n",
    "      Contents of file\n",
    "    And file length\n",
    "  \"\"\"\n",
    "  file = unidecode.unidecode(open(filename).read())\n",
    "  return file, len(file)\n",
    "\n",
    "\n",
    "def char_tensor(string):\n",
    "  \"\"\"\n",
    "  Turning a string into a tensor\n",
    "\n",
    "  Args:\n",
    "    string: string\n",
    "      Input string\n",
    "\n",
    "  Returns:\n",
    "    tensor: torch.tensor\n",
    "      Tensor from input string\n",
    "  \"\"\"\n",
    "  tensor = torch.zeros(len(string)).long()\n",
    "  for c in range(len(string)):\n",
    "    try:\n",
    "      tensor[c] = all_characters.index(string[c])\n",
    "    except:\n",
    "      continue\n",
    "  return tensor\n",
    "\n",
    "\n",
    "def time_since(since):\n",
    "  \"\"\"\n",
    "  Readable time elapsed\n",
    "\n",
    "  Args:\n",
    "    since: time\n",
    "      Input time\n",
    "\n",
    "  Returns:\n",
    "    out: string\n",
    "      Time elapsed since since.\n",
    "  \"\"\"\n",
    "  s = time.time() - since\n",
    "  m = math.floor(s / 60)\n",
    "  s -= m * 60\n",
    "  out = f\"{m}min {s}sec\"\n",
    "  return out\n",
    "\n",
    "\n",
    "def generate(decoder, prime_str='A', predict_len=100,\n",
    "             temperature=0.8,\n",
    "             device='cpu'):\n",
    "  \"\"\"\n",
    "  Function to generate predicted future sequence\n",
    "\n",
    "  Args:\n",
    "    decoder: nn.module\n",
    "      Model\n",
    "    prime_str: string\n",
    "      Prime string [default: A]\n",
    "    predict_len: int\n",
    "      Predict length [default: 100]\n",
    "    temperature: float\n",
    "      Temperature [default: 0.8]\n",
    "    device: string\n",
    "      GPU/CUDA if available, CPU otherwise\n",
    "\n",
    "  Returns:\n",
    "    predicted: string\n",
    "      Predicted sequence\n",
    "  \"\"\"\n",
    "  hidden = decoder.init_hidden(1)\n",
    "  prime_input = char_tensor(prime_str).unsqueeze(0)\n",
    "\n",
    "  hidden = hidden.to(device)\n",
    "  prime_input = prime_input.to(device)\n",
    "  predicted = prime_str\n",
    "\n",
    "  # Use priming string to \"build up\" hidden state\n",
    "  for p in range(len(prime_str) - 1):\n",
    "    _, hidden = decoder(prime_input[:,p], hidden)\n",
    "\n",
    "  inp = prime_input[:,-1]\n",
    "\n",
    "  for p in range(predict_len):\n",
    "    output, hidden = decoder(inp, hidden)\n",
    "\n",
    "    # Sample from the network as a multinomial distribution\n",
    "    output_dist = output.data.view(-1).div(temperature).exp()\n",
    "    top_i = torch.multinomial(output_dist, 1)[0]\n",
    "\n",
    "    # Add predicted character to string and use as next input\n",
    "    predicted_char = all_characters[top_i]\n",
    "    predicted += predicted_char\n",
    "    inp = char_tensor(predicted_char).unsqueeze(0)\n",
    "    inp = inp.to(device)\n",
    "\n",
    "  return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Set random seed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Executing `set_seed(seed=seed)` you are setting the seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Set random seed\n",
    "\n",
    "# @markdown Executing `set_seed(seed=seed)` you are setting the seed\n",
    "\n",
    "# For DL its critical to set the random seed so that students can have a\n",
    "# baseline to compare their results to expected results.\n",
    "# Read more here: https://pytorch.org/docs/stable/notes/randomness.html\n",
    "\n",
    "# Call `set_seed` function in the exercises to ensure reproducibility.\n",
    "import random\n",
    "import torch\n",
    "\n",
    "def set_seed(seed=None, seed_torch=True):\n",
    "  \"\"\"\n",
    "  Function that controls randomness.\n",
    "  NumPy and random modules must be imported.\n",
    "\n",
    "  Args:\n",
    "    seed : Integer\n",
    "      A non-negative integer that defines the random state. Default is `None`.\n",
    "    seed_torch : Boolean\n",
    "      If `True` sets the random seed for pytorch tensors, so pytorch module\n",
    "      must be imported. Default is `True`.\n",
    "\n",
    "  Returns:\n",
    "    Nothing.\n",
    "  \"\"\"\n",
    "  if seed is None:\n",
    "    seed = np.random.choice(2 ** 32)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  if seed_torch:\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "  print(f'Random seed {seed} has been set.')\n",
    "\n",
    "\n",
    "# In case that `DataLoader` is used\n",
    "def seed_worker(worker_id):\n",
    "  \"\"\"\n",
    "  DataLoader will reseed workers following randomness in\n",
    "  multi-process data loading algorithm.\n",
    "\n",
    "  Args:\n",
    "    worker_id: integer\n",
    "      ID of subprocess to seed. 0 means that\n",
    "      the data will be loaded in the main process\n",
    "      Refer: https://pytorch.org/docs/stable/data.html#data-loading-randomness for more details\n",
    "\n",
    "  Returns:\n",
    "    Nothing\n",
    "  \"\"\"\n",
    "  worker_seed = torch.initial_seed() % 2**32\n",
    "  np.random.seed(worker_seed)\n",
    "  random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Set device (GPU or CPU). Execute `set_device()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "#@title Set device (GPU or CPU). Execute `set_device()`\n",
    "# especially if torch modules used.\n",
    "\n",
    "# Inform the user if the notebook uses GPU or CPU.\n",
    "\n",
    "def set_device():\n",
    "  \"\"\"\n",
    "  Set the device. CUDA if available, CPU otherwise\n",
    "\n",
    "  Args:\n",
    "    None\n",
    "\n",
    "  Returns:\n",
    "    Nothing\n",
    "  \"\"\"\n",
    "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "  if device != \"cuda\":\n",
    "    print(\"WARNING: For this notebook to perform best, \"\n",
    "        \"if possible, in the menu under `Runtime` -> \"\n",
    "        \"`Change runtime type.`  select `GPU` \")\n",
    "  else:\n",
    "    print(\"GPU is enabled in this notebook.\")\n",
    "\n",
    "  return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "SEED = 2021\n",
    "set_seed(seed=SEED)\n",
    "DEVICE = set_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Section 1: Recurrent Neural Networks (RNNs)\n",
    "\n",
    "*Time estimate: ~20mins*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Video 1: RNNs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Video 1: RNNs\n",
    "from ipywidgets import widgets\n",
    "\n",
    "out2 = widgets.Output()\n",
    "with out2:\n",
    "  from IPython.display import IFrame\n",
    "  class BiliVideo(IFrame):\n",
    "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
    "      self.id=id\n",
    "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
    "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "  video = BiliVideo(id=f\"BV1L44y1m7PP\", width=730, height=410, fs=1)\n",
    "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
    "  display(video)\n",
    "\n",
    "out1 = widgets.Output()\n",
    "with out1:\n",
    "  from IPython.display import YouTubeVideo\n",
    "  video = YouTubeVideo(id=f\"PsZjS125lLs\", width=730, height=410, fs=1, rel=0)\n",
    "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
    "  display(video)\n",
    "\n",
    "out = widgets.Tab([out1, out2])\n",
    "out.set_title(0, 'Youtube')\n",
    "out.set_title(1, 'Bilibili')\n",
    "\n",
    "# Add event to airtable\n",
    "atform.add_event('Video 1: RNNs')\n",
    "\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "RNNs are compact models that operate over timeseries, and have the ability to remember past input. They also save parameters by using the same weights at every time step.  If you've heard of Transformers, those models don't have this kind of temporal weight sharing, and so they are *much* larger.\n",
    "\n",
    "The code below is adapted from [this github repository](https://github.com/spro/char-rnn.pytorch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# https://github.com/spro/char-rnn.pytorch\n",
    "\n",
    "class CharRNN(nn.Module):\n",
    "  \"\"\"\n",
    "  Recurrent Neural Network Implementation\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, input_size, hidden_size, output_size,\n",
    "               model=\"gru\", n_layers=1):\n",
    "    \"\"\"\n",
    "    Initialise CharRNN parameters\n",
    "\n",
    "    Args:\n",
    "      input_size: int\n",
    "        Size of the input layer.\n",
    "      hidden_size: int\n",
    "        Size of the hidden layers.\n",
    "      output_size: int\n",
    "        Size of the output layer.\n",
    "      model: string\n",
    "        `model` can take the values \"gru\", \"rnn\", \"lstm\". Default is \"gru\".\n",
    "      n_layers: int\n",
    "        Number of layers [default: 1]\n",
    "\n",
    "    Returns:\n",
    "      Nothing\n",
    "    \"\"\"\n",
    "    super(CharRNN, self).__init__()\n",
    "    self.model = model.lower()\n",
    "    self.input_size = input_size\n",
    "    self.hidden_size = hidden_size\n",
    "    self.output_size = output_size\n",
    "    self.n_layers = n_layers\n",
    "\n",
    "    self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "    if self.model == \"gru\":\n",
    "      self.rnn = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "    elif self.model == \"lstm\":\n",
    "      self.rnn = nn.LSTM(hidden_size, hidden_size, n_layers)\n",
    "    elif self.model == \"rnn\":\n",
    "      self.rnn = nn.RNN(hidden_size, hidden_size, n_layers)\n",
    "    self.decoder = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "  def forward(self, input, hidden):\n",
    "    \"\"\"\n",
    "    Forward pass of CharRNN\n",
    "\n",
    "    Args:\n",
    "      input: torch.tensor\n",
    "        Input to CharRNN\n",
    "      hidden: int\n",
    "        Dimension of hidden layer\n",
    "\n",
    "    Returns:\n",
    "      output: torch.tensor\n",
    "        Output of CharRNN\n",
    "      hidden: torch.tensor\n",
    "        Output of CharRNN hidden layer\n",
    "    \"\"\"\n",
    "    batch_size = input.size(0)\n",
    "    encoded = self.encoder(input)\n",
    "    output, hidden = self.rnn(encoded.reshape(1, batch_size, -1), hidden)\n",
    "    output = self.decoder(output.reshape(batch_size, -1))\n",
    "    return output, hidden\n",
    "\n",
    "  def init_hidden(self, batch_size):\n",
    "    \"\"\"\n",
    "    Initialise hidden dimension of CharRNN\n",
    "\n",
    "    Args:\n",
    "      batch_size: int\n",
    "        Batch Size\n",
    "\n",
    "    Returns:\n",
    "      torch.zeros(self.n_layers, batch_size, self.hidden_size), torch.zeros(self.n_layers, batch_size, self.hidden_size) if LSTM\n",
    "      torch.zeros(self.n_layers, batch_size, self.hidden_size) otherwise\n",
    "    \"\"\"\n",
    "    if self.model == \"lstm\":\n",
    "      return (torch.zeros(self.n_layers, batch_size, self.hidden_size), torch.zeros(self.n_layers, batch_size, self.hidden_size))\n",
    "\n",
    "    return torch.zeros(self.n_layers, batch_size, self.hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "This next section of code takes care of training the RNN on several of Mark Twain's books. In this short section, we won't dive into the code, but you'll get to learn a lot more about RNNs in a few days! For now, we are just going to observe the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Run Me to get the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Run Me to get the data\n",
    "import requests\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D1_ConvnetsAndRecurrentNeuralNetworks/static/twain.txt'\n",
    "r = requests.get(url, stream=True)\n",
    "\n",
    "with open('twain.txt', 'wb') as fd:\n",
    "  fd.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "One cool thing about RNNs is that they can be used to _generate_ language based on what the network sees during training. As the network makes predictions, instead of confirming of those predictions are correct against some training text, we just feed them back into the model as the next observed token.  Starting from a random vector for the hidden state, we can generate many original sentences! And what the network generates will reflect the text it was trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# https://github.com/spro/char-rnn.pytorch\n",
    "\n",
    "def random_training_set(file, file_len, chunk_len, batch_size,\n",
    "                        device='cpu', seed=0):\n",
    "  \"\"\"\n",
    "  Generates random training set\n",
    "\n",
    "  Args:\n",
    "    file: string\n",
    "      File\n",
    "    file_len: int\n",
    "      Length of file\n",
    "    chunk_len: int\n",
    "      Length of chunk\n",
    "    batch_size: int\n",
    "      Batch size\n",
    "    device: string\n",
    "      GPU/CUDA if available. CPU otherwise [default: CPU]\n",
    "    seed: int\n",
    "      Set seed for reproducibility [default: 0]\n",
    "\n",
    "  Returns:\n",
    "    inp: torch.tensor\n",
    "      Input tensor\n",
    "    target: torch.tensor\n",
    "      Targets\n",
    "    chunk_len: int\n",
    "      Length of chunk\n",
    "    batch_size: int\n",
    "      Batch size\n",
    "    device: string\n",
    "      GPU/CUDA if available. CPU otherwise [default: CPU]\n",
    "  \"\"\"\n",
    "  random.seed(seed)\n",
    "\n",
    "  inp = torch.LongTensor(batch_size, chunk_len).to(device)\n",
    "  target = torch.LongTensor(batch_size, chunk_len).to(device)\n",
    "\n",
    "  for bi in range(batch_size):\n",
    "    start_index = random.randint(0, file_len - chunk_len - 1)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    chunk = file[start_index:end_index]\n",
    "    inp[bi] = char_tensor(chunk[:-1])\n",
    "    target[bi] = char_tensor(chunk[1:])\n",
    "\n",
    "  return inp, target, chunk_len, batch_size, device\n",
    "\n",
    "\n",
    "def train(decoder, criterion, inp, target, chunk_len, batch_size, device):\n",
    "  \"\"\"\n",
    "  Training function\n",
    "\n",
    "  Args:\n",
    "    decoder: nn.module\n",
    "      Decoder model\n",
    "    criterion: function\n",
    "      Loss function\n",
    "    inp: torch.tensor\n",
    "      Input\n",
    "    target: torch.tensor\n",
    "      Targets\n",
    "    chunk_len: int\n",
    "      Length of chunk\n",
    "    batch_size: int\n",
    "      Batch size\n",
    "    device: string\n",
    "      GPU/CUDA if available. CPU otherwise [default: CPU]\n",
    "\n",
    "\n",
    "  Returns:\n",
    "    Decoder loss\n",
    "  \"\"\"\n",
    "  hidden = decoder.init_hidden(batch_size)\n",
    "  decoder.zero_grad()\n",
    "  loss = 0\n",
    "\n",
    "  for c in range(chunk_len):\n",
    "    output, hidden = decoder(inp[:, c].to(device), hidden.to(device))\n",
    "    loss += criterion(output.reshape(batch_size, -1), target[:,c])\n",
    "\n",
    "  loss.backward()\n",
    "  decoder_optimizer.step()\n",
    "  return loss.item() / chunk_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "First, let's load the text file, and define the model and its hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Reading and un-unicode-encoding data\n",
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "\n",
    "# Load the text file\n",
    "file, file_len = read_file('twain.txt')\n",
    "\n",
    "# Hyperparams\n",
    "batch_size = 50\n",
    "chunk_len = 200\n",
    "model = \"rnn\"  # Other options: `lstm`, `gru`\n",
    "\n",
    "n_layers = 2\n",
    "hidden_size = 200\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Define the model, optimizer, and the loss criterion\n",
    "decoder = CharRNN(n_characters, hidden_size, n_characters,\n",
    "                  model=model, n_layers=n_layers)\n",
    "decoder.to(DEVICE)\n",
    "\n",
    "decoder_optimizer = torch.optim.Adagrad(decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Let's try it! Run the code below. As the network trains, it will output samples of generated text every 25 epochs. Notice that as the training progresses, the model learns to spell short words, then learns to string some words together, and eventually can produce meaningful sentences (sometimes)! Keep in mind that this is a relatively small network, and doesn't employ some of the cool things you'll learn about later in the week (e.g., LSTMs, though you can change that in the code below by changing the value of the `model` variable if you wish!)\n",
    "\n",
    "After running the model, and observing the output, get together with your pod, and talk about what you noticed during training. Did your network produce anything interesting? Did it produce anything characteristic of Twain?  \n",
    "\n",
    "**Note:** training for the full 2000 epochs is likely to take a while, so you may need to stop it before it finishes. If you have time left, set `n_epochs` to 2000 below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "n_epochs = 1000   # Initial was set to 2000\n",
    "\n",
    "print_every = 50  # Frequency of printing the outputs\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "print(f\"Training for {n_epochs} epochs...\\n\")\n",
    "for epoch in tqdm(range(1, n_epochs + 1), position=0, leave=True):\n",
    "  loss = train(decoder, criterion,\n",
    "               *random_training_set(file, file_len, chunk_len, batch_size,\n",
    "                                    device=DEVICE, seed=epoch))\n",
    "  loss_avg += loss\n",
    "\n",
    "  if epoch % print_every == 0:\n",
    "    print(f\"[{time_since(start)} {epoch/n_epochs * 100}%) {loss:.4f}]\")\n",
    "    print(f\"{generate(decoder, prime_str='Wh', predict_len=150, device=DEVICE)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now you can generate more examples using a trained model. Recall that `generate` takes the mentioned below arguments to work:\n",
    "\n",
    "```python\n",
    "generate(decoder, prime_str='A', predict_len=100, temperature=0.8, device='cpu')\n",
    "```\n",
    "\n",
    "Try it by yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "print(f\"{generate(decoder, prime_str='Wh', predict_len=100, device=DEVICE)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Section 2: Power consumption in Deep Learning\n",
    "\n",
    "*Time estimate: ~20mins*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Training NN models can be incredibly costly, both in actual money but also in power consumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Video 2: Carbon Footprint of AI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Video 2: Carbon Footprint of AI\n",
    "from ipywidgets import widgets\n",
    "\n",
    "out2 = widgets.Output()\n",
    "with out2:\n",
    "  from IPython.display import IFrame\n",
    "  class BiliVideo(IFrame):\n",
    "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
    "      self.id=id\n",
    "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
    "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "  video = BiliVideo(id=f\"BV1My4y1j7HJ\", width=730, height=410, fs=1)\n",
    "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
    "  display(video)\n",
    "\n",
    "out1 = widgets.Output()\n",
    "with out1:\n",
    "  from IPython.display import YouTubeVideo\n",
    "  video = YouTubeVideo(id=f\"as6C334LmRs\", width=730, height=410, fs=1, rel=0)\n",
    "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
    "  display(video)\n",
    "\n",
    "out = widgets.Tab([out1, out2])\n",
    "out.set_title(0, 'Youtube')\n",
    "out.set_title(1, 'Bilibili')\n",
    "\n",
    "# Add event to airtable\n",
    "atform.add_event('Video 2: Carbon Footprint of AI')\n",
    "\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Take a few moments to chat with your pod about the following points:\n",
    "* Which societal costs of training do you find most compelling?\n",
    "* When is training an AI model worth the cost?  Who should make that decision?\n",
    "* Should there be additional taxes on energy costs for compute centers? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Exercise 2: Calculate the carbon footprint that your pod generated today.\n",
    "\n",
    "You can use this [online calculator](https://mlco2.github.io/impact/#compute). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Student Response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Student Response\n",
    "from ipywidgets import widgets\n",
    "\n",
    "\n",
    "text=widgets.Textarea(\n",
    "   value='Type your answer here and click on `Submit!`',\n",
    "   placeholder='Type something',\n",
    "   description='',\n",
    "   disabled=False\n",
    ")\n",
    "\n",
    "button = widgets.Button(description=\"Submit!\")\n",
    "\n",
    "display(text,button)\n",
    "\n",
    "def on_button_clicked(b):\n",
    "   atform.add_answer('q1', text.value)\n",
    "   print(\"Submission successful!\")\n",
    "\n",
    "\n",
    "button.on_click(on_button_clicked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Summary\n",
    "\n",
    "What a day!  We've learned a lot!  The basics of CNNs and RNNs, and how changes to architecture that allow models to parameter share can greatly reduce the size of the model.  We learned about convolution and pooling, as well as the basic idea behind RNNs.  To wrap up we thought about the impact of training large NN models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Airtable Submission Link\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# @title Airtable Submission Link\n",
    "from IPython import display as IPydisplay\n",
    "IPydisplay.HTML(\n",
    "   f\"\"\"\n",
    " <div>\n",
    "   <a href= \"{atform.url()}\" target=\"_blank\">\n",
    "   <img src=\"https://github.com/NeuromatchAcademy/course-content-dl/blob/main/tutorials/static/SurveyButton.png?raw=1\"\n",
    " alt=\"button link end of day Survey\" style=\"width:410px\"></a>\n",
    "   </div>\"\"\" )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "W2D1_Tutorial2",
   "provenance": [],
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
